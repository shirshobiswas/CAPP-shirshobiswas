{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm, metrics, tree, \\\n",
    "decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, \\\n",
    "GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, \\\n",
    "OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "f1_score, roc_auc_score, precision_recall_curve\n",
    "import random\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "def define_clfs_params():\n",
    "\n",
    "\n",
    "    clfs = {\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.1, subsample=0.5, \\\n",
    "            max_depth=5, n_estimators=100),\n",
    "        \n",
    "            }\n",
    "\n",
    "    grid = { \n",
    "    \n",
    "    'GB': {'n_estimators': [100], 'learning_rate' : [0.1], 'subsample' : [0.5], 'max_depth': [5]},\n",
    "    \n",
    "           }\n",
    "\n",
    "    return clfs, grid\n",
    "\n",
    "def clf_loop(models_to_run,clfs,grid,X,y):\n",
    "\n",
    "    best_model = ''\n",
    "    best_params = ''\n",
    "    best_auc = -1\n",
    "\n",
    "\n",
    "    with open ('output/results2.csv', 'w') as csvfile:\n",
    "        w = csv.writer(csvfile, delimiter=',')\n",
    "        w.writerow(['Classification_Model', 'Parameters', 'auc', 'time'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "            test_size=0.2, random_state=0)\n",
    "        for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            \n",
    "            current_model = models_to_run[index]\n",
    "            current_params = grid[current_model]\n",
    "\n",
    "            start_time = time.time()\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    print(clf)\n",
    "\n",
    "                    if hasattr(clf,'predict_proba'):\n",
    "                       y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    else: \n",
    "                       y_pred_probs = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "                    threshold = np.sort(y_pred_probs)[::-1][int(.05*len(y_pred_probs))]\n",
    "                    #print (threshold)\n",
    "                    end_time=time.time()\n",
    "                    print(models_to_run[index], \"used:\",end_time-start_time)\n",
    "                    #print (precision_at_k(y_test,y_pred_probs,.05))\n",
    "                    #plot_precision_recall_n(y_test,y_pred_probs,clf)\n",
    "                    current_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "                    if current_auc > best_auc:\n",
    "                        best_model = current_model\n",
    "                        best_params = current_params\n",
    "                        best_pred_y = y_pred_probs\n",
    "                    print(\"AUC:\",current_auc)\n",
    "                    print()\n",
    "                except IndexError as e:\n",
    "                    print ('Error:',e)\n",
    "                    continue\n",
    "                w.writerow([current_model, clf, current_auc, end_time-start_time])\n",
    "    plot_precision_recall_n(y_test, y_pred_probs, best_model)\n",
    "    print(\"~\"*101)\n",
    "    print(best_model,best_params, best_auc)\n",
    "    return best_model, best_params, best_auc, best_pred_y\n",
    "\n",
    "def evaluate(y_true, y_predict):\n",
    "    evaluation = dict()\n",
    "\n",
    "    try:\n",
    "        evaluation['accuracy'] = accuracy_score(y_true, y_predict)\n",
    "        evaluation['precision'] = precision_score(y_true, y_predict)\n",
    "        evaluation['recall'] = recall_score(y_true, y_predict)\n",
    "        evaluation['f1'] = f1_score(y_true, y_predict)\n",
    "        evaluation['area_under_curve'] = roc_auc_score(y_true, y_predict),\n",
    "        evaluation['precision_at_k'] = precision_at_k(y_true,y_predict, 0.05)\n",
    "\n",
    "    except:\n",
    "        print(\"No metrics.\")\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, \\\n",
    "    pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    #plt.savefig(name)\n",
    "    plt.show()\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k):\n",
    "    threshold = np.sort(y_scores)[::-1][int(k*len(y_scores))]\n",
    "    y_pred = np.asarray([1 if i >= threshold else 0 for i in y_scores])\n",
    "    return metrics.precision_score(y_true, y_pred)\n",
    "\n",
    "def get_y_x(df):\n",
    "    y = df['SeriousDlqin2yrs']\n",
    "    df.drop('SeriousDlqin2yrs', axis = 1, inplace = True)\n",
    "    return y, df\n",
    "\n",
    "def main(filename): \n",
    "    clfs,grid = define_clfs_params()\n",
    "    models_to_run=['KNN', 'RF', 'LR', 'GB','DT', 'SVM']\n",
    "\n",
    "    #get X and y\n",
    "    df = pd.read_csv(filename, index_col = 0)\n",
    "    y, X = get_y_x(df)\n",
    "\n",
    "    best_model, best_params, best_auc, best_pred_y = clf_loop(models_to_run,clfs,grid,X,y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing, cross_validation, svm, metrics, tree, \\\n",
    "decomposition, svm\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, \\\n",
    "GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier, \\\n",
    "OrthogonalMatchingPursuit, RandomizedLogisticRegression\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import ParameterGrid\n",
    "from sklearn.metrics import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, \\\n",
    "f1_score, roc_auc_score, precision_recall_curve\n",
    "import random\n",
    "import pylab as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import csv\n",
    "import time\n",
    "\n",
    "\n",
    "def define_clfs_params():\n",
    "\n",
    "\n",
    "    clfs = {\n",
    "        'GB': GradientBoostingClassifier(learning_rate=0.1, subsample=0.5, \\\n",
    "            max_depth=5, n_estimators=100),\n",
    "        \n",
    "            }\n",
    "\n",
    "    grid = { \n",
    "    \n",
    "    'GB': {'n_estimators': [100], 'learning_rate' : [0.1], 'subsample' : [0.5], 'max_depth': [5]},\n",
    "    \n",
    "           }\n",
    "\n",
    "    return clfs, grid\n",
    "\n",
    "def clf_loop(models_to_run,clfs,grid,X,y):\n",
    "\n",
    "    best_model = ''\n",
    "    best_params = ''\n",
    "    best_auc = -1\n",
    "\n",
    "\n",
    "    with open ('output/results2.csv', 'w') as csvfile:\n",
    "        w = csv.writer(csvfile, delimiter=',')\n",
    "        w.writerow(['Classification_Model', 'Parameters', 'auc', 'time'])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, \\\n",
    "            test_size=0.2, random_state=0)\n",
    "        for index,clf in enumerate([clfs[x] for x in models_to_run]):\n",
    "            \n",
    "            current_model = models_to_run[index]\n",
    "            current_params = grid[current_model]\n",
    "\n",
    "            start_time = time.time()\n",
    "            print(models_to_run[index])\n",
    "            parameter_values = grid[models_to_run[index]]\n",
    "            for p in ParameterGrid(parameter_values):\n",
    "                try:\n",
    "                    clf.set_params(**p)\n",
    "                    print(clf)\n",
    "\n",
    "                    if hasattr(clf,'predict_proba'):\n",
    "                       y_pred_probs = clf.fit(X_train, y_train).predict_proba(X_test)[:,1]\n",
    "                    else: \n",
    "                       y_pred_probs = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "                    threshold = np.sort(y_pred_probs)[::-1][int(.05*len(y_pred_probs))]\n",
    "                    #print (threshold)\n",
    "                    end_time=time.time()\n",
    "                    print(models_to_run[index], \"used:\",end_time-start_time)\n",
    "                    #print (precision_at_k(y_test,y_pred_probs,.05))\n",
    "                    #plot_precision_recall_n(y_test,y_pred_probs,clf)\n",
    "                    current_auc = roc_auc_score(y_test, y_pred_probs)\n",
    "\n",
    "                    if current_auc > best_auc:\n",
    "                        best_model = current_model\n",
    "                        best_params = current_params\n",
    "                        best_pred_y = y_pred_probs\n",
    "                    print(\"AUC:\",current_auc)\n",
    "                    print()\n",
    "                except IndexError as e:\n",
    "                    print ('Error:',e)\n",
    "                    continue\n",
    "                w.writerow([current_model, clf, current_auc, end_time-start_time])\n",
    "    plot_precision_recall_n(y_test, y_pred_probs, best_model)\n",
    "    print(\"~\"*101)\n",
    "    print(best_model,best_params, best_auc)\n",
    "    return best_model, best_params, best_auc, best_pred_y\n",
    "\n",
    "def evaluate(y_true, y_predict):\n",
    "    evaluation = dict()\n",
    "\n",
    "    try:\n",
    "        evaluation['accuracy'] = accuracy_score(y_true, y_predict)\n",
    "        evaluation['precision'] = precision_score(y_true, y_predict)\n",
    "        evaluation['recall'] = recall_score(y_true, y_predict)\n",
    "        evaluation['f1'] = f1_score(y_true, y_predict)\n",
    "        evaluation['area_under_curve'] = roc_auc_score(y_true, y_predict),\n",
    "        evaluation['precision_at_k'] = precision_at_k(y_true,y_predict, 0.05)\n",
    "\n",
    "    except:\n",
    "        print(\"No metrics.\")\n",
    "\n",
    "    return evaluation\n",
    "\n",
    "def plot_precision_recall_n(y_true, y_prob, model_name):\n",
    "    from sklearn.metrics import precision_recall_curve\n",
    "    y_score = y_prob\n",
    "    precision_curve, recall_curve, \\\n",
    "    pr_thresholds = precision_recall_curve(y_true, y_score)\n",
    "    precision_curve = precision_curve[:-1]\n",
    "    recall_curve = recall_curve[:-1]\n",
    "    pct_above_per_thresh = []\n",
    "    number_scored = len(y_score)\n",
    "    for value in pr_thresholds:\n",
    "        num_above_thresh = len(y_score[y_score>=value])\n",
    "        pct_above_thresh = num_above_thresh / float(number_scored)\n",
    "        pct_above_per_thresh.append(pct_above_thresh)\n",
    "    pct_above_per_thresh = np.array(pct_above_per_thresh)\n",
    "    plt.clf()\n",
    "    fig, ax1 = plt.subplots()\n",
    "    ax1.plot(pct_above_per_thresh, precision_curve, 'b')\n",
    "    ax1.set_xlabel('percent of population')\n",
    "    ax1.set_ylabel('precision', color='b')\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(pct_above_per_thresh, recall_curve, 'r')\n",
    "    ax2.set_ylabel('recall', color='r')\n",
    "    \n",
    "    name = model_name\n",
    "    plt.title(name)\n",
    "    #plt.savefig(name)\n",
    "    plt.show()\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k):\n",
    "    threshold = np.sort(y_scores)[::-1][int(k*len(y_scores))]\n",
    "    y_pred = np.asarray([1 if i >= threshold else 0 for i in y_scores])\n",
    "    return metrics.precision_score(y_true, y_pred)\n",
    "\n",
    "def get_y_x(df):\n",
    "    y = df['SeriousDlqin2yrs']\n",
    "    df.drop('SeriousDlqin2yrs', axis = 1, inplace = True)\n",
    "    return y, df\n",
    "\n",
    "def main(filename): \n",
    "    clfs,grid = define_clfs_params()\n",
    "    models_to_run=[ 'GB']\n",
    "\n",
    "    #get X and y\n",
    "    df = pd.read_csv(filename, index_col = 0)\n",
    "    y, X = get_y_x(df)\n",
    "\n",
    "    best_model, best_params, best_auc, best_pred_y = clf_loop(models_to_run,clfs,grid,X,y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB\n",
      "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
      "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
      "              min_samples_leaf=1, min_samples_split=2,\n",
      "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "              random_state=None, subsample=0.5, verbose=0,\n",
      "              warm_start=False)\n",
      "('GB', 'used:', 37.34626913070679)\n",
      "('AUC:', 0.85500104865259563)\n",
      "()\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "('GB', {'n_estimators': [100], 'subsample': [0.5], 'learning_rate': [0.1], 'max_depth': [5]}, -1)\n"
     ]
    }
   ],
   "source": [
    "main('training_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('cs-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import sys\n",
    "import random\n",
    "from __future__ import division\n",
    "from numpy import nan\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category = DeprecationWarning)\n",
    "\n",
    "#Evaluation metrics is a separate pyhton file containing some useful functions for evaluation of different methods. One of the function is evaluating a binary classifier\n",
    "from EvaluationMetrics import bin_classif_eval\n",
    "\n",
    "#This function reads in a csv file as a dataframe\n",
    "def readcsvfile(file_name):\n",
    "    df =  pd.read_csv(file_name, header = 0)\n",
    "#We discussed in the previous TA session that NA values in some fields were coded numerically.\n",
    "#I replace these numerical values with 'nan'\n",
    "\n",
    "    df = df.replace({'NumberofTimes90DaysLate':{98:nan, 97:nan, 96:nan}, 'NumberofTime60-89DaysPastDueNotWorse':{98:nan, 97:nan, 96:nan}, 'NumberofTime30-59DaysPastDueNotWorse':{98:nan, 97:nan, 96:nan}, 'NumberofDependents':{20:nan}, 'age':{0:nan}})\n",
    "    return df\n",
    "\n",
    "\n",
    "#This function describes a datarame i.e. it prints column names, head and tail of the data,summary statistics, number of missing values in each column and the correlation matrix\n",
    "def summary_statistics(df):\n",
    "    pd.set_option('display.width', 18)\n",
    "    print 'Column Names:', \"\\n\", df.columns.values\n",
    "    print 'First Few Rows of Data:', \"\\n\", df.head()\n",
    "    print 'Last Few Rows of Data:', \"\\n\", df.tail()\n",
    "    print 'Summary Statistics:', \"\\n\", df.describe(include = 'all')\n",
    "    print 'Number of Missing Values:', \"\\n\", df.isnull().sum()\n",
    "    \n",
    "    for col_name in df:\n",
    "        print ('Data Type %s: %s' %(col_name, df[col_name].dtype))\n",
    "        \n",
    "    print 'Correlation Matrix :', \"\\n\", df.corr().unstack()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def plot_histogram(df, hist_var):\n",
    "    fig = df[hist_var].hist()\n",
    "    fig.set_title('Histogram for ' + hist_var)\n",
    "    plt.draw()\n",
    "    plt.savefig(hist_var)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_bar(df, bar_var):\n",
    "    fig =df.groupby(bar_var).size().plot(kind='bar')\n",
    "    fig.set_xlabel(bar_var) #defines the x axis label\n",
    "    fig.set_ylabel('Number of Observations') #defines y axis label\n",
    "    fig.set_title(bar_var+' Distribution') #defines graph title\n",
    "    plt.draw()\n",
    "    plt.savefig(bar_var)\n",
    "    plt.close('all')\n",
    "    \n",
    "histogram_variables = ['serious_dlqin2yrs','revolving_utilization_of_unsecured_lines', 'age', 'number_of_time30-59_days_past_due_not_worse', 'debt_ratio', 'monthly_income', 'number_of_open_credit_lines_and_loans', 'number_of_times90_days_late', 'number_real_estate_loans_or_lines', 'number_of_time60-89_days_past_due_not_worse', 'number_of_dependents']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bar_variables = ['serious_dlqin2yrs']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#This function prints histograms for each column of a data frame\n",
    "def data_histogram(df):\n",
    "    df.hist()\n",
    "    plt.savefig('histograms.png')\n",
    "    \n",
    "#This function plots grouped columns with mean of the group\n",
    "def plot_by_group_mean(df,columns, group_by_col):\n",
    "    df[columns].groupby(group_by_col).mean().plot()\n",
    "    file_name = 'plot_by_' + group_by_col + '.png'\n",
    "    plt.savefig(file_name)\n",
    "    \n",
    "\n",
    "#This function converts a categorical variable in a data frame into binary dummies and then drops the original categorical variable\n",
    "def categorical_to_binary_dummies(df,Category):\n",
    "    dummies = pd.get_dummies(df['Category'], Category, drop_first = True)\n",
    "    df = df.join(dummies)\n",
    "    return df\n",
    "    \n",
    "#This function takes a dataframe and a column name and discretizes a continuous variable into bins\n",
    "def discretize_bins_values(df,col_name, bins, verbose = False):\n",
    "    new_col = 'bins_' + str(col_name)\n",
    "    df[new_col] = pd.cut(df[col_name], bins = bins, include_lowest = True, labels = False)\n",
    "    \n",
    "    if verbose:\n",
    "        print pd.value_counts(data[new_col])\n",
    "        \n",
    "    return new_col\n",
    "\n",
    "#This function takes a dataframe and a column name and discretizes a continuous variable into  bins based on quantiles\n",
    "def discretize_bins_quantiles(df,col_name,number_of_bins, verbose = False):\n",
    "    new_col = 'bins_' + str(col_name)\n",
    "    df[new_col] = pd.qcut(df[col_name],number_of_bins, labels = False)\n",
    "    \n",
    "    if verbose:\n",
    "        print pd.value_counts(data[new_col])\n",
    "        \n",
    "    return new_col\n",
    "\n",
    "\n",
    "#This function returns the log of a column. useful to get log income\n",
    "def log_column(df,col_name):\n",
    "    log_col = 'log_' + str(col_name)\n",
    "    df[log_col] = df[col_name].apply(lambda x: np.log(x+1))\n",
    "    return log_col\n",
    "#This function plots the histogram of a log variable\n",
    "\n",
    "def plot_log(df,var):\n",
    "    lb = 0\n",
    "    ub = 15\n",
    "    increment = 0.5\n",
    "    plt.gca().set_xscale('log')\n",
    "    fig = df[var].hist(bins = np.exp(np.arrange(lb,ub,increment)))\n",
    "    fig.set_xlabel('log'+var)\n",
    "    plt.savefig('log'+var)\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "##Imputing Missing values in Training Data Set and Filling in Missing values in testing dataset with stored values in Testing Dataset\n",
    "\n",
    "#This function fills the missing values in a column fn a datafraframe with mean, median or mode\n",
    "\n",
    "def impute_missing_values(df,var,method):\n",
    "   \n",
    "        if method == 'mean':\n",
    "               mean = df[var].mean()\n",
    "               return mean\n",
    "\n",
    "        elif method == 'median':\n",
    "               median = df[var].median()\n",
    "               return median\n",
    "\n",
    "        elif method == 'mode':\n",
    "               mode = df[var].mode[0]\n",
    "               return mode\n",
    "\n",
    "\n",
    "#This function fills the missing values in a column fn a datafraframe with a specified value\n",
    "\n",
    "def replace_missing_values(df,var,value):\n",
    "         df[var] = df[var].fillna(value)\n",
    "         return df\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('cs-training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ImputedMonthlyIncome = df_train['MonthlyIncome'].median()\n",
    "ImputedNumberOfDependents = df_train['NumberOfDependents'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = replace_missing_values(df_test, ['MonthlyIncome'], ImputedMonthlyIncome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test = replace_missing_values(df_test, ['NumberOfDependents'], ImputedNumberOfDependents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_var_name = 'SeriousDlqin2yrs'\n",
    "X_var_names = [\n",
    "  'RevolvingUtilizationOfUnsecuredLines',\n",
    "  'age',\n",
    "  'NumberOfTime30-59DaysPastDueNotWorse',\n",
    "  'DebtRatio',\n",
    "  'MonthlyIncome',\n",
    "  'NumberOfOpenCreditLinesAndLoans',\n",
    "  'NumberOfTimes90DaysLate',\n",
    "  'NumberRealEstateLoansOrLines',\n",
    "  'NumberOfTime60-89DaysPastDueNotWorse',\n",
    "  'NumberOfDependents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
    "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
    "              min_samples_leaf=1, min_samples_split=2,\n",
    "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
    "              random_state=None, subsample=0.5, verbose=0,\n",
    "              warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('training_imputed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(init=None, learning_rate=0.1, loss='deviance',\n",
       "              max_depth=5, max_features=None, max_leaf_nodes=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              random_state=None, subsample=0.5, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X=df[X_var_names], y=df.SeriousDlqin2yrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_test_pred_probs =final_model.predict_proba(X=df_test[X_var_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
